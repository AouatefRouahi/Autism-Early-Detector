{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e14dd1e-9f87-463c-bc42-636cee9551e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text-based Model: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264518ed-0e22-4656-826c-bc090264a4f8",
   "metadata": {},
   "source": [
    "-------   \n",
    "\n",
    "In this part of the project, we want to dig deeper into the collected and preprocessed data to extract more relevant data for the training phase.  \n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affc902a-9c16-4326-9c19-2dc0b02e0c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\softeam2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Generic libs\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# predefined modules\n",
    "from modules import NLP_Functions as NLP_F\n",
    "\n",
    "#global params\n",
    "dataset_path = 'data/preprocessed_autism.csv'\n",
    "new_dataset_path = 'data/autism_with_metadata.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2606fa2-aaf8-4d6a-9b19-c4f1bce615b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71cec764-2c9a-4f5a-9232-c12f9a12d2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>speech</th>\n",
       "      <th>ASD</th>\n",
       "      <th>abs_age</th>\n",
       "      <th>clean_annotated_speech</th>\n",
       "      <th>lemmatized_speech</th>\n",
       "      <th>meaningful_speech</th>\n",
       "      <th>structured_speech</th>\n",
       "      <th>stemmed_lemmatized_speech</th>\n",
       "      <th>stemmed_structured_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eigsti</td>\n",
       "      <td>5;03.10</td>\n",
       "      <td>female</td>\n",
       "      <td>\\tokay .</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>okay</td>\n",
       "      <td>okay</td>\n",
       "      <td>okay</td>\n",
       "      <td>okay</td>\n",
       "      <td>okay</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eigsti</td>\n",
       "      <td>5;03.10</td>\n",
       "      <td>female</td>\n",
       "      <td>\\tdid you see this ?</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>did you see this</td>\n",
       "      <td>do you see this</td>\n",
       "      <td>do you see this</td>\n",
       "      <td>do you see this</td>\n",
       "      <td>do you see thi</td>\n",
       "      <td>do you see thi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eigsti</td>\n",
       "      <td>5;03.10</td>\n",
       "      <td>female</td>\n",
       "      <td>\\tyeah .</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>yeah</td>\n",
       "      <td>yeah</td>\n",
       "      <td>yeah</td>\n",
       "      <td>yeah</td>\n",
       "      <td>yeah</td>\n",
       "      <td>yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eigsti</td>\n",
       "      <td>5;03.10</td>\n",
       "      <td>female</td>\n",
       "      <td>\\txxx let's see +...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uni let's see inq</td>\n",
       "      <td>uni let us see inq</td>\n",
       "      <td>uni let us see inq</td>\n",
       "      <td>uni let we see inq</td>\n",
       "      <td>uni let us see inq</td>\n",
       "      <td>uni let we see inq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eigsti</td>\n",
       "      <td>5;03.10</td>\n",
       "      <td>female</td>\n",
       "      <td>\\txxx .</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uni</td>\n",
       "      <td>uni</td>\n",
       "      <td>uni</td>\n",
       "      <td>uni</td>\n",
       "      <td>uni</td>\n",
       "      <td>uni</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name      age     sex                speech  ASD  abs_age  \\\n",
       "0  Eigsti  5;03.10  female              \\tokay .    1      5.0   \n",
       "1  Eigsti  5;03.10  female  \\tdid you see this ?    1      5.0   \n",
       "2  Eigsti  5;03.10  female              \\tyeah .    1      5.0   \n",
       "3  Eigsti  5;03.10  female  \\txxx let's see +...    1      5.0   \n",
       "4  Eigsti  5;03.10  female               \\txxx .    1      5.0   \n",
       "\n",
       "  clean_annotated_speech   lemmatized_speech   meaningful_speech  \\\n",
       "0                   okay                okay                okay   \n",
       "1       did you see this     do you see this     do you see this   \n",
       "2                   yeah                yeah                yeah   \n",
       "3      uni let's see inq  uni let us see inq  uni let us see inq   \n",
       "4                    uni                 uni                 uni   \n",
       "\n",
       "    structured_speech stemmed_lemmatized_speech stemmed_structured_speech  \n",
       "0                okay                      okay                      okay  \n",
       "1     do you see this            do you see thi            do you see thi  \n",
       "2                yeah                      yeah                      yeah  \n",
       "3  uni let we see inq        uni let us see inq        uni let we see inq  \n",
       "4                 uni                       uni                       uni  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(dataset_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b80bcb2-e5f5-47f9-ab69-305178d45e30",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extract new features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f39d51-d118-4cbe-8cce-07bd58f2e212",
   "metadata": {},
   "source": [
    "> We want to extract **metadata** as **quantities** from the different forms of speech created in the previous phase. This metadata informs us about the linguistic skills level of each child.\n",
    "> * **Length of clean annotated speech**: how expressive the child is ?\n",
    "> * **Length of meaningful speech**: how developed is his vocabulary ?\n",
    "> * **Length of structured speech**: how structured is his speech ?\n",
    "\n",
    "Note that, by length we mean the number of words. Hence, we do not distinguish between short and long words. We excluded the annotations key words from the count. \n",
    "\n",
    "> * **Occurrence number of each annotation** (number of repetition, number of babbling and so on): this is a very important piece of information because these annotations contain the common signs of linguistic disorders.\n",
    "> * **Number of different used words**: how wide-ranging is the child's vocabulary ?\n",
    "> * **Speech density** : number of characters used in the speech without considering whitespaces and annotations. This informs us whether the child tends to use short or long words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ae90e4-ef1c-4146-955c-1cd22262c173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Compute speech length 1/3\n",
      "Step 1: Compute speech length 2/3\n",
      "Step 1: Compute speech length 3/3\n",
      "Step 2: Compute number of each annotation\n",
      "Step 3: convert age to months\n",
      "Step 4: compute number of different used words\n",
      "Step 5: compute density of speech\n",
      "Save!! ...\n",
      "Features Extracting is done, you find your extracted data at data/autism_with_metadata.csv\n",
      "Wall time: 6min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NLP_F.extract_features(data, new_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be06eed0-316d-438d-930a-3fcb3354f522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>speech</th>\n",
       "      <th>ASD</th>\n",
       "      <th>abs_age</th>\n",
       "      <th>clean_annotated_speech</th>\n",
       "      <th>lemmatized_speech</th>\n",
       "      <th>meaningful_speech</th>\n",
       "      <th>structured_speech</th>\n",
       "      <th>...</th>\n",
       "      <th>n_uni</th>\n",
       "      <th>n_rep</th>\n",
       "      <th>n_inq</th>\n",
       "      <th>n_ono</th>\n",
       "      <th>n_hes</th>\n",
       "      <th>n_mis</th>\n",
       "      <th>n_disf</th>\n",
       "      <th>age_in_months</th>\n",
       "      <th>n_diff_words</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eigsti</td>\n",
       "      <td>5;03.10</td>\n",
       "      <td>0</td>\n",
       "      <td>\\tokay .</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>okay</td>\n",
       "      <td>okay</td>\n",
       "      <td>okay</td>\n",
       "      <td>okay</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eigsti</td>\n",
       "      <td>5;03.10</td>\n",
       "      <td>0</td>\n",
       "      <td>\\tdid you see this ?</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>did you see this</td>\n",
       "      <td>do you see this</td>\n",
       "      <td>do you see this</td>\n",
       "      <td>do you see this</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eigsti</td>\n",
       "      <td>5;03.10</td>\n",
       "      <td>0</td>\n",
       "      <td>\\tyeah .</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>yeah</td>\n",
       "      <td>yeah</td>\n",
       "      <td>yeah</td>\n",
       "      <td>yeah</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eigsti</td>\n",
       "      <td>5;03.10</td>\n",
       "      <td>0</td>\n",
       "      <td>\\txxx let's see +...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uni let's see inq</td>\n",
       "      <td>uni let us see inq</td>\n",
       "      <td>uni let us see inq</td>\n",
       "      <td>uni let we see inq</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eigsti</td>\n",
       "      <td>5;03.10</td>\n",
       "      <td>0</td>\n",
       "      <td>\\txxx .</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uni</td>\n",
       "      <td>uni</td>\n",
       "      <td>uni</td>\n",
       "      <td>uni</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     name      age  sex                speech  ASD  abs_age  \\\n",
       "0  Eigsti  5;03.10    0              \\tokay .    1      5.0   \n",
       "1  Eigsti  5;03.10    0  \\tdid you see this ?    1      5.0   \n",
       "2  Eigsti  5;03.10    0              \\tyeah .    1      5.0   \n",
       "3  Eigsti  5;03.10    0  \\txxx let's see +...    1      5.0   \n",
       "4  Eigsti  5;03.10    0               \\txxx .    1      5.0   \n",
       "\n",
       "  clean_annotated_speech   lemmatized_speech   meaningful_speech  \\\n",
       "0                   okay                okay                okay   \n",
       "1       did you see this     do you see this     do you see this   \n",
       "2                   yeah                yeah                yeah   \n",
       "3      uni let's see inq  uni let us see inq  uni let us see inq   \n",
       "4                    uni                 uni                 uni   \n",
       "\n",
       "    structured_speech  ... n_uni n_rep  n_inq  n_ono  n_hes  n_mis  n_disf  \\\n",
       "0                okay  ...     0     0      0      0      0      0       0   \n",
       "1     do you see this  ...     0     0      0      0      0      0       0   \n",
       "2                yeah  ...     0     0      0      0      0      0       0   \n",
       "3  uni let we see inq  ...     1     0      1      0      0      0       0   \n",
       "4                 uni  ...     1     0      0      0      0      0       0   \n",
       "\n",
       "   age_in_months  n_diff_words  density  \n",
       "0           63.0             1        4  \n",
       "1           63.0             4       13  \n",
       "2           63.0             1        4  \n",
       "3           63.0             3        8  \n",
       "4           63.0             0        0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_metadata = pd.read_csv(new_dataset_path)\n",
    "data_with_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c62c77b1-df1f-4180-bc94-d443c03265df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'age', 'sex', 'speech', 'ASD', 'abs_age',\n",
       "       'clean_annotated_speech', 'lemmatized_speech', 'meaningful_speech',\n",
       "       'structured_speech', 'stemmed_lemmatized_speech',\n",
       "       'stemmed_structured_speech', 'len_clean_annotated_speech',\n",
       "       'len_meaningful_speech', 'len_structured_speech', 'n_bab', 'n_gue',\n",
       "       'n_uni', 'n_rep', 'n_inq', 'n_ono', 'n_hes', 'n_mis', 'n_disf',\n",
       "       'age_in_months', 'n_diff_words', 'density'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_metadata.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
