{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "933a611f-ec9b-41dc-a6cf-97ef048e21c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text-based Model: Training Models: Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a38233-6aa1-4abb-958d-d4681f60ead1",
   "metadata": {},
   "source": [
    "-------   \n",
    "> In this last part, we will **tune the hyperparameters** of the chosen model (**RandomForestClassifier**) to find out the set of parameters that give the best results.\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca8c3ca-d41f-419e-b2c1-6a4b46c26fed",
   "metadata": {},
   "source": [
    "<pre>\n",
    "üìù <b>Note</b>\n",
    "<div style=\"background-color:#C2F2ED;\">\n",
    "The term <b>best</b> algorithm is used to refer to the algorithm that gives the best results <b>among the evaluated algorithms</b> in this project and not among all the classificatiion algorithms.\n",
    "</div> </pre> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "442813bb-183b-4cac-a50c-d6632584a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generic libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# predefined modules\n",
    "from modules import Train_Functions as Train_F\n",
    "\n",
    "# ML libs \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#global params\n",
    "dataset_path = 'data/autism_with_metadata.csv'\n",
    "\n",
    "model_path = 'models/'\n",
    "report_path = 'models/'\n",
    "\n",
    "val_ratio = 0.2\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fd2a6a-fe97-4145-aca8-3f3a7c78f1ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0abdae6a-436f-40b8-9722-a6d98493d65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>speech</th>\n",
       "      <th>ASD</th>\n",
       "      <th>abs_age</th>\n",
       "      <th>clean_annotated_speech</th>\n",
       "      <th>lemmatized_speech</th>\n",
       "      <th>meaningful_speech</th>\n",
       "      <th>structured_speech</th>\n",
       "      <th>...</th>\n",
       "      <th>n_uni</th>\n",
       "      <th>n_rep</th>\n",
       "      <th>n_inq</th>\n",
       "      <th>n_ono</th>\n",
       "      <th>n_hes</th>\n",
       "      <th>n_mis</th>\n",
       "      <th>n_disf</th>\n",
       "      <th>age_in_months</th>\n",
       "      <th>n_diff_words</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eigsti</td>\n",
       "      <td>5;03.10</td>\n",
       "      <td>0</td>\n",
       "      <td>\\tokay .</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>okay</td>\n",
       "      <td>okay</td>\n",
       "      <td>okay</td>\n",
       "      <td>okay</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eigsti</td>\n",
       "      <td>5;03.10</td>\n",
       "      <td>0</td>\n",
       "      <td>\\tdid you see this ?</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>did you see this</td>\n",
       "      <td>do you see this</td>\n",
       "      <td>do you see this</td>\n",
       "      <td>do you see this</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eigsti</td>\n",
       "      <td>5;03.10</td>\n",
       "      <td>0</td>\n",
       "      <td>\\tyeah .</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>yeah</td>\n",
       "      <td>yeah</td>\n",
       "      <td>yeah</td>\n",
       "      <td>yeah</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eigsti</td>\n",
       "      <td>5;03.10</td>\n",
       "      <td>0</td>\n",
       "      <td>\\txxx let's see +...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uni let's see inq</td>\n",
       "      <td>uni let us see inq</td>\n",
       "      <td>uni let us see inq</td>\n",
       "      <td>uni let we see inq</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eigsti</td>\n",
       "      <td>5;03.10</td>\n",
       "      <td>0</td>\n",
       "      <td>\\txxx .</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uni</td>\n",
       "      <td>uni</td>\n",
       "      <td>uni</td>\n",
       "      <td>uni</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     name      age  sex                speech  ASD  abs_age  \\\n",
       "0  Eigsti  5;03.10    0              \\tokay .    1      5.0   \n",
       "1  Eigsti  5;03.10    0  \\tdid you see this ?    1      5.0   \n",
       "2  Eigsti  5;03.10    0              \\tyeah .    1      5.0   \n",
       "3  Eigsti  5;03.10    0  \\txxx let's see +...    1      5.0   \n",
       "4  Eigsti  5;03.10    0               \\txxx .    1      5.0   \n",
       "\n",
       "  clean_annotated_speech   lemmatized_speech   meaningful_speech  \\\n",
       "0                   okay                okay                okay   \n",
       "1       did you see this     do you see this     do you see this   \n",
       "2                   yeah                yeah                yeah   \n",
       "3      uni let's see inq  uni let us see inq  uni let us see inq   \n",
       "4                    uni                 uni                 uni   \n",
       "\n",
       "    structured_speech  ... n_uni n_rep  n_inq  n_ono  n_hes  n_mis  n_disf  \\\n",
       "0                okay  ...     0     0      0      0      0      0       0   \n",
       "1     do you see this  ...     0     0      0      0      0      0       0   \n",
       "2                yeah  ...     0     0      0      0      0      0       0   \n",
       "3  uni let we see inq  ...     1     0      1      0      0      0       0   \n",
       "4                 uni  ...     1     0      0      0      0      0       0   \n",
       "\n",
       "   age_in_months  n_diff_words  density  \n",
       "0           63.0             1        4  \n",
       "1           63.0             4       13  \n",
       "2           63.0             1        4  \n",
       "3           63.0             3        8  \n",
       "4           63.0             0        0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(dataset_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59108a2e-37f3-4717-b962-b80fcc94c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train_F.missing(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce06922b-e6bd-4696-939b-499f161e3b5c",
   "metadata": {},
   "source": [
    "## Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c857052-4242-4bec-96f8-aa8e5f49413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. drop null values\n",
    "data.dropna(subset=['clean_annotated_speech'], inplace=True)\n",
    "\n",
    "# define the features and the target\n",
    "numerical_features = ['sex','age_in_months','len_clean_annotated_speech',\n",
    "       'len_meaningful_speech', 'len_structured_speech', 'n_bab', 'n_gue',\n",
    "       'n_uni', 'n_rep', 'n_inq', 'n_ono', 'n_hes', 'n_mis', 'n_disf',\n",
    "        'n_diff_words', 'density']\n",
    "\n",
    "nlp_features = ['clean_annotated_speech']\n",
    "\n",
    "y = data['ASD'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27a16c2-114e-4a41-a2f5-5cd2ac519e4e",
   "metadata": {},
   "source": [
    "## Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1c8eaa6-3d3f-479c-8e4f-11105452724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the textual features and the numerical features\n",
    "cols = numerical_features + nlp_features\n",
    "X = data[cols]\n",
    "\n",
    "# split the data into training and validation subsets\n",
    "X_train, X_val, y_train, y_val = Train_F.train_val(X, y, val_ratio) \n",
    "\n",
    "# Training pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    [('tfidfV', TfidfVectorizer(), 'clean_annotated_speech')], \n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "combined_clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor), \n",
    "        (\"classifier\", RandomForestClassifier(n_jobs=-1, random_state=seed, verbose=3))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe3c05-cbfd-400a-be89-871a635d3c29",
   "metadata": {},
   "source": [
    "## Tuning Chosen Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89fc7c90-3d3c-4e89-be62-2c41ffb837d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classifier', 'classifier__bootstrap', 'classifier__ccp_alpha', 'classifier__class_weight', 'classifier__criterion', 'classifier__max_depth', 'classifier__max_features', 'classifier__max_leaf_nodes', 'classifier__max_samples', 'classifier__min_impurity_decrease', 'classifier__min_impurity_split', 'classifier__min_samples_leaf', 'classifier__min_samples_split', 'classifier__min_weight_fraction_leaf', 'classifier__n_estimators', 'classifier__n_jobs', 'classifier__oob_score', 'classifier__random_state', 'classifier__verbose', 'classifier__warm_start']\n"
     ]
    }
   ],
   "source": [
    "print(Train_F.check_params_exist(combined_clf, 'classifier'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c2a0ff-a969-4008-8d0b-5fdb2030dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    #tfidf hyperparams\n",
    "    'preprocessor__tfidfV__max_df': np.linspace(0.6, 1.0, 3),   #ignore terms that appear in more than x% of the documents\n",
    "    'preprocessor__tfidfV__min_df': np.linspace(0.1, 0.4, 3),   #ignore terms that appear in less than x% of the documents\n",
    "    'preprocessor__tfidfV__max_features': [5_000, 10_000],      #  only consider the k top max_features ordered by term frequency across the corpus.\n",
    "    #classifier hyperparams\n",
    "    'classifier__max_depth': [5,15],\n",
    "    'classifier__max_features': [2, 3],\n",
    "    'classifier__min_samples_leaf': [3, 4, 5],\n",
    "    'classifier__min_samples_split': [8, 10, 12],\n",
    "    'classifier__n_estimators': [10, 50, 100, 200],\n",
    "    }\n",
    "best_clf = Train_F.grid_search(combined_clf, X_train, X_val,y_train, y_val, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ef4af-04d1-4218-b79d-9f9e20c7d77c",
   "metadata": {},
   "source": [
    "## Evaluating Best Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62933500-ea31-4c59-87ce-0c00266e070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_F.classifier(best_clf, 'RandomForestClassifier', X_train, y_train, X_val, y_val, stage='tuned', intermediate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dc03bb-aa13-42ac-af10-1c912a1027e2",
   "metadata": {},
   "source": [
    "------------\n",
    "## Conclusion \n",
    "<pre><div style=\"background-color:#F7D819;\">\n",
    "The model can detect <b>74 among 100 children with ASD</b>  with an <b>86% of precision</b> As a first attempt, these results are encouraging.\n",
    "</div></pre>\n",
    "------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
